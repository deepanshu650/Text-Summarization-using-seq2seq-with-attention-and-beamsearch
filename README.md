# Text-Summarization-using-seq2seq-with-attention-and-beamsearch

Text Summarization using sequence to sequence based model with attention mechanism and beam search inference 

The dataset used is a subset of the gigaword dataset and can be found at [here](https://drive.google.com/file/d/0B6N7tANPyVeBNmlSX19Ld2xDU1E/view)
It contains 3,803,955 parallel source & target examples for training and 189,649 examples for validation out of which 80000 is used for training and 1000 for validation.



